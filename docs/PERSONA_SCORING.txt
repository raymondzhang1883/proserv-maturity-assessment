PROFESSIONAL SERVICES KPI MATURITY ASSESSMENT
PERSONA SCORING METHODOLOGY

This document details the exact calculation methodology for determining persona scores (P0-P4) 
based on KPI maturity assessment responses. Lead generation scoring is documented separately.

================================================================================
OVERVIEW
================================================================================

The assessment evaluates 5 core dimensions of KPI maturity based on 5 questions:
1. Coverage Score (Weight: 1.0) - Which KPIs are tracked (A1)
2. Confidence Score (Weight: 1.0) - Data reliability and trust (B2, B4, B5)
3. Latency Score (Weight: 0.7) - Reporting speed (B3)
4. Automation Score (Weight: 1.0) - Technology infrastructure (C6, C7, C8)
5. Forecast Score (Weight: 1.0) - Predictive capabilities (D13)

Total possible score: 47 points
Persona assignment based on total score thresholds.

================================================================================
QUESTIONS USED IN SCORING
================================================================================

Only 5 questions are used for persona scoring calculations:

**A1: Which performance indicators does your team review at least monthly?**
*(Multi-select - Select all that apply)*
- Billable-utilization %
- Average bill / realized rate
- Project gross-margin %
- Revenue-forecast accuracy
- Bench cost (idle hours × loaded rate)
- Client satisfaction / NPS
- None of the above or I don't know

**B2: How confident are you in those numbers?**
*(Slider: 0-10 scale)*
- Left Label: Not confident
- Right Label: Completely confident

**B3: How soon after month-end are your core KPIs ready?**
- Same day
- Within 1 week
- 1–2 weeks
- More than 2 weeks / Not sure

**B4: Roughly what share of your KPI data still needs manual fixes every month?**
- Nothing
- Very little
- Around half
- More than half

**B5: Which data-quality issues are you most concerned about?**
*(Multi-select - Select all that apply)*
- Duplicate records
- Missing fields
- Inconsistent definitions
- Human error
- None - our data is reliable

**C6: Where do you compile or view KPIs today?**
*(Multi-select - Select all that apply)*
- PSA built-in dashboards
- Spreadsheets
- BI platform (Tableau / Power BI / Looker)
- We don't compile them consistently

**C7: How would you describe your data architecture?**
- Modern cloud warehouse with APIs
- Traditional database plus some integrations
- Multiple disconnected systems
- Mainly spreadsheets
- Unsure

**C8: Do you have an internal data / BI team?**
- Yes – dedicated
- Limited bandwidth
- None

**D13: Which statement best matches your forecasting ability?**
- We don't forecast
- Manual quarterly forecast in spreadsheets
- Automated monthly forecast in BI tool
- Scenario simulations & what-if analysis

================================================================================
INDIVIDUAL SCORE CALCULATIONS
================================================================================

1. COVERAGE SCORE (0-10 points, Weight: 1.0)
   Question: A1 - Which KPIs do you review monthly?
   
   Calculation:
   - Count selected KPIs (excluding "None of the above" responses)
   - Divide by total possible KPIs (6)
   - Multiply by 10 and round
   
   Formula: Math.round((validKPIs.length / 6) × 10)
   
   Examples:
   - 0 KPIs selected → 0 points
   - 3 KPIs selected → 5 points  
   - 6 KPIs selected → 10 points

2. CONFIDENCE SCORE (0-10 points, Weight: 1.0)
   Questions: B2 (slider 0-10), B4 (manual work), B5 (data quality)
   
   Calculation:
   - Start with B2 confidence rating (0-10)
   - Apply manual work penalty: subtract (manual_base_value × 2)
   - Add data quality bonus: +2 if "None - our data is reliable" selected
   - Cap result between 0-10
   
   Manual Work Base Values (from scoringRules.js):
   - "Nothing" → 0 (penalty: 0 × 2 = 0)
   - "Very little" → 1 (penalty: 1 × 2 = -2 points)
   - "Around half" → 2 (penalty: 2 × 2 = -4 points)
   - "More than half" → 3 (penalty: 3 × 2 = -6 points)
   
   Formula: Math.max(0, Math.min(10, B2_rating - (manual_base_value × 2) + quality_bonus))
   
   Examples:
   - B2=8, "Very little" manual work, reliable data → 8 - 2 + 2 = 8 points
   - B2=6, "Around half" manual work, no quality bonus → 6 - 4 + 0 = 2 points

3. LATENCY SCORE (1-10 points, Weight: 0.7)
   Question: B3 - How soon after month-end are KPIs ready?
   
   Direct mapping:
   - "Same day" → 10 points
   - "Within 1 week" → 8 points
   - "1–2 weeks" → 5 points
   - "More than 2 weeks / Not sure" → 1 point

4. AUTOMATION SCORE (1-10 points, Weight: 1.0)
   Questions: C6 (tools), C7 (architecture), C8 (team)
   
   Two-stage calculation:
   
   Stage 1: Check for perfect configuration matches (exact array matching)
   Perfect combinations receive exact scores:
   - ['BI platform (Tableau / Power BI / Looker)'] + 'Modern cloud warehouse with APIs' + 'Yes – dedicated' → 10 points
   - ['BI platform (Tableau / Power BI / Looker)'] + 'Modern cloud warehouse with APIs' + 'Limited bandwidth' → 8 points
   - ['BI platform (Tableau / Power BI / Looker)'] + 'Traditional database plus some integrations' + 'Yes – dedicated' → 7 points
   - ['BI platform (Tableau / Power BI / Looker)'] + 'Traditional database plus some integrations' + 'Limited bandwidth' → 5 points
   - ['PSA built-in dashboards'] + 'Modern cloud warehouse with APIs' + 'Yes – dedicated' → 6 points
   - ['PSA built-in dashboards'] + 'Multiple disconnected systems' + 'Limited bandwidth' → 3 points
   - ['PSA built-in dashboards', 'Spreadsheets'] + 'Multiple disconnected systems' + 'None' → 2 points
   - ['Spreadsheets'] + 'Mainly spreadsheets' + 'None' → 1 point
   
   Stage 2: Weighted scoring for partial matches (if no perfect match)
   Base score: 1 point
   Add points for:
   - 'BI platform (Tableau / Power BI / Looker)' in tools → +3 points
   - 'PSA built-in dashboards' in tools → +2 points
   - 'Modern cloud warehouse with APIs' architecture → +3 points
   - 'Traditional database plus some integrations' architecture → +1 point
   - 'Yes – dedicated' team → +2 points
   - 'Limited bandwidth' team → +1 point
   
   Final result capped at 10 points: Math.min(10, score)

5. FORECAST SCORE (1-10 points, Weight: 1.0)
   Question: D13 - Forecasting capability
   
   Direct mapping:
   - "We don't forecast" → 1 point
   - "Manual quarterly forecast in spreadsheets" → 4 points
   - "Automated monthly forecast in BI tool" → 7 points
   - "Scenario simulations & what-if analysis" → 10 points

================================================================================
TOTAL MATURITY SCORE CALCULATION
================================================================================

Formula:
Total = Math.round((Coverage × 1.0) + (Confidence × 1.0) + (Latency × 0.7) + (Automation × 1.0) + (Forecast × 1.0))

Maximum possible: (10 × 1.0) + (10 × 1.0) + (10 × 0.7) + (10 × 1.0) + (10 × 1.0) = 47 points

Example calculation:
- Coverage: 8 points (from A1 - 5 out of 6 KPIs selected)
- Confidence: 6 points (from B2=8, B4="Very little", B5=no quality bonus: 8-2+0=6)
- Latency: 5 points (from B3="1–2 weeks")
- Automation: 7 points (from C6, C7, C8 - matches TRADITIONAL_BI_DEDICATED config)
- Forecast: 4 points (from D13="Manual quarterly forecast in spreadsheets")

Total = Math.round((8 × 1.0) + (6 × 1.0) + (5 × 0.7) + (7 × 1.0) + (4 × 1.0))
Total = Math.round(8 + 6 + 3.5 + 7 + 4) = Math.round(28.5) = 29 points

================================================================================
PERSONA ASSIGNMENT THRESHOLDS
================================================================================

Based on total maturity score:

P4: Strategic / Value Multiplier (42-47 points)
- Advanced analytics with real-time data
- Sophisticated forecasting models
- Data infrastructure as competitive differentiator

P3: Predictive / Optimized (32-41 points)  
- Meaningful insights with good automation
- Business unit alignment
- Applied data for forecasting and modeling

P2: Integrated / Insight-driven (22-31 points)
- Centralized reporting from multiple sources
- Data informs weekly decision-making
- Trusted reporting infrastructure

P1: Standardized / Foundational (11-21 points)
- Core metrics tracked with defined KPIs
- Heavy reliance on manual processes
- Basic reporting infrastructure

P0: Ad Hoc / Fire-fighting (0-10 points)
- Spreadsheet-based reporting
- Manual data collection
- Minimal system alignment

================================================================================
IMPLEMENTATION NOTES
================================================================================

Code Location: src/services/scoringEngine.js
Configuration: src/config/scoringRules.js, src/config/personas.js
Persona Logic: src/services/personaEngine.js
Questions Definition: src/config/questions.js

The scoring system is deterministic and reproducible. All weights and thresholds
are configurable through the scoring rules configuration files.

Questions E2 (company size), E15 (operational challenge), C9 (business unit visibility),
and D11 (data usage) exist in the assessment but are NOT used in persona scoring.
They are used for lead scoring, recommendations, and business context only.

Missing KPIs are tracked separately for recommendation purposes but do not
affect the core persona score calculation.

Total scores are rounded to the nearest integer for persona assignment.